{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d714d57c-1585-44fd-8a58-05c7b22fffc0",
   "metadata": {},
   "source": [
    "## Container Objects\n",
    "\n",
    "*Container Objects* adalah obyek yang mempunyai sifat sebagai penampung, berisi lebih dari satu obyek. Untuk memahami *container objects*, perlu dipahami gambaran umum arsitektur dari spaCy sebagai berikut:\n",
    "\n",
    "![Arsitektur spaCy](spacy-arch.jpg)\n",
    "\n",
    "Sumber bacaan: https://spacy.io/api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74528d0f",
   "metadata": {},
   "source": [
    "### Container Objects 1 - **Language**\n",
    "\n",
    "Pertama kita harus pahami dulu tentang **Language**, sila baca (https://spacy.io/api/language)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3fb12c-89db-4900-b593-6c894f7ab85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.lang.en.English object at 0x0000027C196BC130>\n",
      "<spacy.strings.StringStore object at 0x0000027C272D1540>\n",
      "83839\n",
      "Is 'speech' an English word?: True\n",
      "Is 'mengapa' an English word?: False\n",
      "Is 'tanya' an English word?: True\n",
      "0 10:25\n",
      "1 Shana\n",
      "2 slopes\n",
      "3 Stamford\n",
      "4 Wilsonian\n",
      "5 woodbridge\n",
      "6 richest\n",
      "7 nickeled\n",
      "8 antiwar\n",
      "9 Fireside\n"
     ]
    }
   ],
   "source": [
    "# Definisi language - menggunakan spacy.load\n",
    "import spacy\n",
    "import itertools\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# --- sampai di sini\n",
    "\n",
    "print(nlp)\n",
    "\n",
    "print(nlp.vocab.strings)\n",
    "\n",
    "print(len(nlp.vocab.strings))\n",
    "words = set(nlp.vocab.strings)\n",
    "word = 'speech'\n",
    "print(f\"Is '{word}' an English word?: {word in words}\")\n",
    "word = 'mengapa'\n",
    "print(f\"Is '{word}' an English word?: {word in words}\")\n",
    "\n",
    "word = 'tanya' #Tanya dianggap sebagai nama dalam bahasa inggris \n",
    "print(f\"Is '{word}' an English word?: {word in words}\")\n",
    "\n",
    "for i, val in enumerate(itertools.islice(words, 10)):\n",
    "    print(i, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0861afc-2933-4d27-a5cd-c76babbbf7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.lang.en.English object at 0x0000027C1967F940>\n"
     ]
    }
   ],
   "source": [
    "# Definisi language - cara lain\n",
    "import spacy\n",
    "\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "print(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e26beed7-9598-461b-8e1d-4da153816448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.language.Language object at 0x0000027C27FF3AF0>\n"
     ]
    }
   ],
   "source": [
    "# Jika ingin menggunakan API untuk language - vocab\n",
    "# tanpa definisi bahasa tertentu\n",
    "# (membangun dari awal)\n",
    "\n",
    "from spacy.vocab import Vocab\n",
    "from spacy.language import Language\n",
    "nlp = Language(Vocab())\n",
    "print(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef20b59-75f5-46f3-9c43-192325613dea",
   "metadata": {},
   "source": [
    "**Penting**: kelas *Language* akan memproses teks dan menghasilkan obyek **Doc**. **Doc** merupakan *container objects*. Kita akan mempelajari sedikit demi sedikit dari arsitektur tersebut, dimulai dari *container objects*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b3488a-5c0c-4c11-8870-6a4bca915a37",
   "metadata": {},
   "source": [
    "### Container Objects 2 - **Doc**\n",
    "\n",
    "Sumber bacaan: https://spacy.io/api/doc\n",
    "\n",
    "Merupakan *container* untuk mengakses anotasi linguistik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0e7f092-bfab-4916-847b-2ff26469f9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "Doc\n",
      "is\n",
      "a\n",
      "sequence\n",
      "of\n",
      "Token\n",
      "objects\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# doc = nlp(\"A Doc is a sequence of Token\")\n",
    "doc = nlp(\"A Doc is a sequence of Token objects\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c43e479-be6d-4389-8b28-530fb6bad51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 5\n",
      "world 5\n",
      "! 1\n",
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi Doc - cara lain\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "words = [\"hello\", \"world\", \"!\"]\n",
    "spaces = [True, False, False]\n",
    "#spaces = [False, True, False]\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "\n",
    "for token in doc:\n",
    "    print(token, len(token))\n",
    "    \n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3685fde-523d-4f14-aba6-7fc4e0456309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "Token\n",
      "Doc is a sequence of\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"A Doc is a sequence of Token objects\")\n",
    "\n",
    "print(doc[0].text)\n",
    "print(doc[-2].text)\n",
    "span = doc[1:6]\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b86580d-570d-4582-b36d-cafffea4948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Doc', 'is', 'a', 'sequence', 'of', 'Token', 'objects']\n"
     ]
    }
   ],
   "source": [
    "print([t.text for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b4f4c7-fd2e-4c45-9141-521a1d94c39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1334d45b-537a-49c6-820a-350527fde25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "(None, None, <function <lambda> at 0x0000027C1967CE50>, None)\n"
     ]
    }
   ],
   "source": [
    "# set_extension\n",
    "\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "city_getter = lambda doc: any(city in doc.text for city in (\"Ternate\", \"Paris\", \"Berlin\"))\n",
    "Doc.set_extension(\"has_city\", getter=city_getter, force=True)\n",
    "doc = nlp(\"I like New York\")\n",
    "print(doc._.has_city)\n",
    "extension = Doc.get_extension(\"has_city\")\n",
    "print(extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c4d5aa-7b5a-42bd-83af-f57d1ca7c439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York 7 15 GPE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I like New York\")\n",
    "span = doc.char_span(7, 15, label=\"GPE\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "131bf384-4d26-40c8-b932-0d4c80bd4768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Best PERSON\n"
     ]
    }
   ],
   "source": [
    "# set entity and its label\n",
    "from spacy.tokens import Span\n",
    "\n",
    "doc = nlp(\"Mr. Best flew to New York on Saturday morning.\")\n",
    "\n",
    "doc.set_ents([Span(doc, 0, 2, \"PERSON\")])\n",
    "#doc.set_ents([Span(doc, 0, 2, \"CITY\")])\n",
    "ents = list(doc.ents)\n",
    "\n",
    "for word in ents:\n",
    "    print(word.text, word.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15895c22-21ff-4dce-ba5f-63ce14058eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8840670285788055\n",
      "0.8840670285788055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EVANGS~1\\AppData\\Local\\Temp/ipykernel_7220/3927645350.py:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  apples_oranges = apples.similarity(oranges)\n",
      "C:\\Users\\EVANGS~1\\AppData\\Local\\Temp/ipykernel_7220/3927645350.py:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  oranges_apples = oranges.similarity(apples)\n"
     ]
    }
   ],
   "source": [
    "# Doc similarity\n",
    "apples = nlp(\"I like apples\")\n",
    "oranges = nlp(\"I like oranges\")\n",
    "\n",
    "apples_oranges = apples.similarity(oranges)\n",
    "oranges_apples = oranges.similarity(apples)\n",
    "\n",
    "print(apples_oranges)\n",
    "print(oranges_apples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432ea56-8918-4f06-9bfb-715c8abea91b",
   "metadata": {},
   "source": [
    "### Container Objects 3 - **DocBin**\n",
    "\n",
    "Sumber bacaan: https://spacy.io/api/docbin\n",
    "\n",
    "Digunakan untuk *packing* obyek Doc untuk serialisasi biner. Serialisasi yang digunakan adalah [msgpack](https://msgpack.org/index.html) yang dikompres menggunakan gzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e36413fd-78eb-4954-a660-a260ff588cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coba\n",
      "iseng\n",
      "cetak\n",
      "hasil\n",
      "kalimat\n",
      "ini\n",
      "ya\n",
      "...\n",
      "Coba\n",
      "iseng\n",
      "cetak\n",
      "hasil\n",
      "kalimat\n",
      "ini\n",
      "ya\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import DocBin\n",
    "\n",
    "doc_bin = DocBin(attrs=[\"LEMMA\"])\n",
    "#doc = nlp(\"The DocBin class lets you efficiently serialize the information from a collection of Doc objects.\")\n",
    "doc = nlp(\"Coba iseng cetak hasil kalimat ini ya...\")\n",
    "doc_bin.add(doc)\n",
    "for token in doc:\n",
    "    print(token)  \n",
    "doc_bin.to_disk(\"./data.spacy\")\n",
    "\n",
    "doc_bin = DocBin().from_disk(\"./data.spacy\")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58d598-7ee9-4bd5-817c-c837dbc366eb",
   "metadata": {},
   "source": [
    "File yang dihasilkan:\n",
    "\n",
    "```\n",
    "$ ls -la\n",
    "total 64\n",
    "...\n",
    "...\n",
    "-rw-r--r--  1 bpdp bpdp   602 Jan 19 18:08 data.spacy\n",
    "...\n",
    "...\n",
    "$```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac7e82-52c7-4e13-b2f8-53b5d546cc1b",
   "metadata": {},
   "source": [
    "### Container Objects 4 - **Lexeme**\n",
    "\n",
    "Sumber bacaan: https://spacy.io/api/lexeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca4cdd1c-a278-4f07-82dc-a1e86581b742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 4690420944186131903 X I I True False True en\n",
      "love 3702023516439754181 xxxx l ove True False False en\n",
      "Coffee 3474706295102377020 Xxxxx C fee True False True en\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"I love Coffee\")\n",
    "for word in doc:\n",
    "    lexeme = doc.vocab[word.text]\n",
    "    print(lexeme.text, lexeme.orth, lexeme.shape_, lexeme.prefix_, lexeme.suffix_,\n",
    "            lexeme.is_alpha, lexeme.is_digit, lexeme.is_title, lexeme.lang_)\n",
    "    \n",
    "# orth => orthographic features, representasi text dalam hash\n",
    "# shape_ => bentuk teks, karakter => X atau x, hanya 4 awal. Jika numerik: d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642262b1-af97-4223-be4c-fb9bf3558acd",
   "metadata": {},
   "source": [
    "### Container Objects Lain\n",
    "\n",
    "Masih ada beberapa container objects:\n",
    "1. Example: merupakan koleksi dari anotasi pelatihan. https://spacy.io/api/example\n",
    "2. Span: potongan dari obyek Doc. https://spacy.io/api/span\n",
    "3. SpanGroup: sekumpulan dari span, bisa diberi nama: https://spacy.io/api/spangroup\n",
    "4. Token: https://spacy.io/api/token"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
