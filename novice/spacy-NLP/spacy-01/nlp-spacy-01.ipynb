{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc14ec7f-7d5f-4b17-ab9d-3ba11a892ff8",
   "metadata": {},
   "source": [
    "# Memahami Computational Linguistics, Ruang Lingkup NLP, serta Mulai Menggunakan spaCy\n",
    "\n",
    "## Materi\n",
    "\n",
    "1. Memahami Bahasa Natural / *Natural Language*, Komponen Bahasa, dan Linguistik.\n",
    "2. Pengertian serta Keterkaitan CL dan NLP\n",
    "3. Ruang Lingkup NLP\n",
    "4. Tools untuk NLP\n",
    "5. spaCy dan Ekosistem spaCy\n",
    "6. Instalasi spaCy\n",
    "7. Memulai spaCy\n",
    "\n",
    "## Memahami Bahasa Natural / *Natural Language*, Komponen Bahasa, dan Linguistik\n",
    "\n",
    "Bahasa Natural: bahasa yang dikembangkan oleh manusia melalui penggunaan yang alami serta komunikasi, bukan dengan melalui proses konstruksi dan pembuatan secara sengaja. \n",
    "\n",
    "Untuk lebih mendalami bahasa, diperlukan pemahaman tentang filosofi bahasa yang terutama terkait dengan 4 hal:\n",
    "\n",
    "1. Sumber makna dalam suatu bahasa: terkait dengan sintaksis, semantik, tata bahasa (*grammar*), serta *parse trees*.\n",
    "2. Penggunaan bahasa: bagaimana bahasa digukan dalam berbagai skenario komunikasi. *Speech Acts* merupakan bagian besar dari penggunaan bahasa. *Speech Acts*:\n",
    "    * Locutionary acts: actual delivery of sentence, pengiriman pesan sesungguhnya.\n",
    "    * Illocutionary acts: semantik dan intensi dari kalimat yang disampaikan. Ada 5 intensi:\n",
    "        * Assertives: menghasilkan nilai benar atau salah, atau hal yang memang sudah umum diketahui dan kemudian disampaikan.\n",
    "        * Directives: meminta melakukan sesuatu\n",
    "        * Commissives: *commit* dari pembicara untuk melakukan sesuatu di masa yang akan datang.\n",
    "        * Expressives: mengekspresikasn sesuatu terkait dengan suatu peristiwa tertentu.\n",
    "        * Declarations: mendeklarasikan sesuatu yang mengubah dunia (tidak harus besar, misal menyatakan bahwa surat perjanjian sah atau tidak sah).\n",
    "    * Perlocutionary acts: efek dari kalimat tersebut.\n",
    "3. Kognisi Bahasa: fungsi kognitif dari otak untuk memahami dan menginterpretasikan bahasa.\n",
    "4. Relasi antara bahasa dengan realitas: segitiga referensi / segitiga semiotika / segitiga semantik.\n",
    "\n",
    "Untuk memahami bahasa, kita harus memahami berbagai komponen bahasa. Berbagai komponen bahasa serta hal-hal terkait bahasa ini secara ilmiah dipelajari pada bidang kajian **Linguistik**. Secara umum, komponen dari bahasa yang menjadi pembahasan linguistik adalah:\n",
    "\n",
    "1. *Phonetics*: studi terkait properti akustik dari suara yang dikeluarkan saat terjadi pembicaraan.\n",
    "2. *Phonology*: studi terkait pola suara seperti interpretasi pikiran manusia dan digunakan untuk membedakan *phoneme*. *Phoneme* merupakan unit terkecil bahasa yang membedakan satu kata dengan kata lain. Contoh: tap dengan tab, *phoneme* ada pada p dan b.\n",
    "3. *Syntax*: studi terkait dengan struktur kalimat, frase, serta kata.\n",
    "4. *Semantics*: studi untuk mempelajari makna dalam bahasa, terbagi menjadi *lexical* (makna kata) dan *compositional* (makna kombinasi kata).\n",
    "5. *Morphology*: studi untuk mempelajari *morpheme* (unit terkecil yang mempunyai makna). Morfem bukan kata, karena kata selalu bisa berdiri sendiri, sementara morfem belum tentu. Contoh: **unbreakable** terdiri atas 3 morfem: un-, break, -able.\n",
    "6. *Lexicon*: studi untuk mempelajari *vocabulary* dari suatu bahasa maupun suatu cabang pengetahuan tertentu. Contoh, di *lexicon* hukum, palu adalah palu hakim, di *lexicon* pertukangan, palu adalah peralatan pertukangan.\n",
    "7. *Pragmatics*: studi untuk mempelajari makna dengan menggunakan faktor-faktor linguistik maupun non-linguistik.\n",
    "8. *Discourse Analysis*: studi untuk mempelajari bahasa dan pertukaran informasi dalam suatu percakapan.\n",
    "9. *Stylistic*: studi untuk mempelajari bahasa, terkait dengan gaya penulisan.\n",
    "10. *Semiotics*: studi untuk mempelajari *signs, symbols*, dan *sign-process* serta bagaimana hal-tersebut menghasilkan makna.\n",
    "\n",
    "## Pengertian serta Keterkaitan CL dan NLP\n",
    "\n",
    "### Computational Linguistics (CL) \n",
    "\n",
    "CL adalah:\n",
    "\n",
    "* *...the scientific study of language from a computational perspective. Computational linguists are interested in providing computational models of various kinds of linguistic phenomena.*\n",
    "* ...studi ilmiah bahasa dari perspektif komputasi. *Computational Linguist* tertarik untuk menyediakan model komputasi dari berbagai jenis fenomena linguistik.\n",
    "\n",
    "Peneliti dan ahli dalam CL sering disebut dengan *computational linguist*. Sampai saat ini belum ada istilah dalam bahasa Indonesia yang setara dengan istilah tersebut. Istilah paling mendekati: *ahli komputasi bahasa*. Organisasi profesi untuk mereka yang berkecimpung di bidang ini: ACL (Association for Computational Linguistics - https://www.aclweb.org/). Jurnal untuk bidang ini dan didirikan serta dikelola oleh ACL adalah [Journal of Computational Linguistics](https://direct.mit.edu/coli).\n",
    "\n",
    "Saat ini, ada 2 bagian besar dari CL: \n",
    "1. Theoretical CL: teori tentang grammar dan semantik dengan menggunakan pendekatan *formal logic* dan *symbolic / knowledge-based*.\n",
    "2. Applied CL: machine learning untuk berbagai fenomena linguistik.\n",
    "\n",
    "CL juga mempunyai tujuan untuk mendukung penelitian di bidang linguistik.\n",
    "\n",
    "### Natural Language Processing (NLP)\n",
    "\n",
    "Merupakan gabungan dari linguistik, AI, dan ilmu komputer dalam kaitannya dengan rekayasa software untuk memproses dan menganalisis data bahasa natural manusia.\n",
    "\n",
    "### Keterkaitan CL dan NLP\n",
    "\n",
    "**Catatan**: saat ini, istilah CL dan NLP sering dipertukarkan dan kemungkinan akan seperti itu. \n",
    "\n",
    "CL merupakan sisi yang lebih ke riset dan mempunyai ruang lingkup yang lebih luas daripada NLP. Misal: pemodelan dan identifikasi suatu *language family*. Sementara itu, NLP lebih ke sisi *engineering* terhadap data bahasa natural manusia dan melakukan berbagai hal untuk menghasilkan keluaran tertentu terhadap data bahasa natural manusia tersebut. NLP menggunakan berbagai teknik serta algoritma dari CL untuk memproses data bahasa natural manusia, sementara CL sering menggunakan NLP untuk keperluan sisi *engineering* dari domain CL.\n",
    "\n",
    "## Ruang Lingkup NLP\n",
    "\n",
    "NLP mempunyai 3 sisi besar:\n",
    "\n",
    "1. *Speech Recognition*: mengenali ungkapan lisan dan menterjemahkan ungkapan tersebut ke dalam teks.\n",
    "2. *Natural Language Understanding*: memahami arti yang terkandung dalam kalimat atau kesatuan kalimat bahasa natural manusia.\n",
    "3. *Natural Language Generation*: menghasilkan bahasa natural manusia dari data (linguistik maupun non linguistik).\n",
    "\n",
    "Dari 3 sisi besar tersebut, muncul berbagai tasks NLP:\n",
    "\n",
    "1. *Text and Speech Processing*: memproses teks dalam bentuk non teks (dokumen PDF, gambar berupa tulisan, dst) maupun pembicaraan (suara).\n",
    "2. *Morphological Analysis*: meproses struktur dari kata (morfologi - lema, *part-of-speech*, stem)\n",
    "3. *Syntactic Analysis*: grammar (tata bahasa) dan parsing\n",
    "4. *Lexical Semantics*: makna dari kata (semantics, Named-Entity-Recognition, *terminology extraction*, *word-sense*)\n",
    "5. *Relational Semantics*: keterkaitan antar *entity* dalam suatu kalimat.\n",
    "6. *Discourse*: makna yang tidak hanya sekedar satu kata, satu rangkaian kata, atau satu kalimat, tetapi bisa ke lebih dari satu kalimat.\n",
    " \n",
    "\n",
    "## Tools untuk NLP\n",
    "\n",
    "1. NLTK (https://www.nltk.org/) - Python\n",
    "2. Apache OpenNLP (https://opennlp.apache.org/) - JVM\n",
    "3. Standford CoreNLP (https://stanfordnlp.github.io/CoreNLP/) - JVM, tetapi banyak *wrapper* yang dibuat di bahasa pemrograman lain. Lihat https://stanfordnlp.github.io/CoreNLP/other-languages.html\n",
    "4. spaCy (https://spacy.io/) - Python\n",
    "5. TextBlob (https://textblob.readthedocs.io/en/dev/) - Python\n",
    "6. Gensim (https://github.com/RaRe-Technologies/gensim) - Python\n",
    "\n",
    "## spaCy dan Ekosistem spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445a550-d5b4-457f-b758-b6827c39a72f",
   "metadata": {},
   "source": [
    "Gambaran umum: https://github.com/zimera-school/materi-pembelajaran/tree/main/python-nlp\n",
    "Website penting:\n",
    "1. [spaCy](https://spacy.io)\n",
    "2. [Explosion AI - Pembuat spaCy](https://explosion.ai)\n",
    "3. [GitHub Explosion AI](https://github.com/explosion)\n",
    "4. [GitHub - source code spaCy](https://github.com/explosion/spaCy)\n",
    "5. [Contoh struktur direktori untuk proyek spaCy](https://github.com/explosion/projects/tree/v3/pipelines)\n",
    "6. [End-to-end NLP workflows from prototype to production](https://github.com/explosion/projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a74400c-569d-462b-aad7-49b35c872b18",
   "metadata": {},
   "source": [
    "## Instalasi spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a59170-bf58-44f9-be3e-ae8deb955fe9",
   "metadata": {},
   "source": [
    "Instalasi spaCy melibatkan instalasi spaCy serta model yang nantinya akan digunakan. Model merupakan bagian dari spaCy yang digunakan sebagai *pre-trained pipelines*, artinya sudah disediakan oleh spaCy untuk keperluan pengolahan teks. Model disediakan sesuai dengan bahasa tertentu karena setiap pemrosesan data bahasa merupakan data bahasa tertentu. Sebagai contoh, untuk  memproses data teks dalam bahasa Inggris, kita memerlukan berbagai aturan bahasa Inggris beserta lema, NER, tagger, dan lain-lain.\n",
    "\n",
    "### Instalasi spaCy\n",
    "\n",
    "Jika menggunakan Conda:\n",
    "\n",
    "```\n",
    "$ conda install spacy\n",
    "```\n",
    "\n",
    "Jika menggunakan pip:\n",
    "\n",
    "```\n",
    "$ pip install spacy\n",
    "```\n",
    "\n",
    "Setelah itu, install model. Setiap model biasanya terdiri atas *-sm (small), -md (medium),* dan *-lg (large)*. Semua di-*train* menggunakan data yang sama, dengan kondisi sama. Perbedaan terletak pada *vector* yang dimasukkan dan digunakan sebagai *features* dan akan mempengaruhi akurasi.\n",
    "\n",
    "Untuk install model:\n",
    "\n",
    "```\n",
    "$ python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "**Catatan**: ganti sm dengan md serta lg untuk install model dengan *features* medium dan large.\n",
    "\n",
    "Jika menggunakan Conda, bisa juga dengan menggunakan (ganti sm dengan md dan lg untuk install medium dan large):\n",
    "\n",
    "```\n",
    "$ conda install spacy-model-en_core_web_sm\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc99db-b4ef-4838-8f1b-b002dc13cbec",
   "metadata": {},
   "source": [
    "## Memulai spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83d8b5e-7ce0-4c47-890f-756cff5f75c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "world\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# Mosly taken from https://course.spacy.io/en/ with modification\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Create a blank English nlp object\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Created by processing a string of text with the nlp object\n",
    "doc = nlp(\"Hello world!\")\n",
    "\n",
    "# Iterate over tokens in a Doc\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aecb943-fc2a-465e-b39e-5978fa62284d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n"
     ]
    }
   ],
   "source": [
    "# Index into the Doc to get a single Token\n",
    "token = doc[1]\n",
    "\n",
    "# Get the token text via the .text attribute\n",
    "print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6349cee8-5ecf-4034-83bc-5e104c6e9723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world!\n"
     ]
    }
   ],
   "source": [
    "# Hello -> 0\n",
    "# World -> 1\n",
    "# ! -> 2\n",
    "# doc[1:3] -> posisi index ke 1 sampai 2 (3 tidak ikut)\n",
    "\n",
    "# A slice from the Doc is a Span object\n",
    "span = doc[1:3]\n",
    "\n",
    "# Get the span text via the .text attribute\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384ea6ef-3b3f-48c0-bd82-4a192f7e7c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "Text:     ['My', 'name', 'Evangs', 'Mailoa', '.', 'I', 'loves', 'sport', 'and', 'computer', '.', '1', '2', '3']\n",
      "is_alphanumeric: [True, True, True, True, False, True, True, True, True, True, False, False, False, False]\n",
      "is_punctuation: [False, False, False, False, True, False, False, False, False, False, True, False, False, False]\n",
      "like_num: [False, False, False, False, False, False, False, False, False, False, False, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "# Tipe dari token, daftar lengkap dari is_*** ada di https://spacy.io/api/token\n",
    "\n",
    "doc = nlp(\"My name Evangs Mailoa. I loves sport and computer. 1 2 3\")\n",
    "print(\"Index:   \", [token.i for token in doc])\n",
    "print(\"Text:    \", [token.text for token in doc])\n",
    "\n",
    "print(\"is_alphanumeric:\", [token.is_alpha for token in doc]) #cek alfanumerik\n",
    "print(\"is_punctuation:\", [token.is_punct for token in doc]) #cek tanda baca\n",
    "print(\"like_number:\", [token.like_num for token in doc]) #cek angka atau bukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe395021-304e-4f22-933e-65652afb5d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "like AUX\n",
      "playing VERB\n",
      "soccer NOUN\n"
     ]
    }
   ],
   "source": [
    "# Jenis kata, menggunakan pre-trained pipelines\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load the small English pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process a text\n",
    "# doc = nlp(\"She ate the pizza\")\n",
    "doc = nlp(\"I like playing soccer\")\n",
    "\n",
    "\n",
    "# Iterate over the tokens\n",
    "for token in doc:\n",
    "    # Print the text and the predicted part-of-speech tag\n",
    "    print(token.text, token.pos_)\n",
    "\n",
    "# PRON => pronoun (kata ganti)\n",
    "# AUX => kata bantu\n",
    "# VERB => kata kerja\n",
    "# DET => determinant (see: https://en.wikipedia.org/wiki/English_determiners)\n",
    "# NOUN => kata benda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f086b546-074b-4a2b-a85a-a1c0edb38751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due ADP prep brought\n",
      "to ADP pcomp Due\n",
      "an DET det crisis\n",
      "injury NOUN compound crisis\n",
      "crisis NOUN pobj Due\n",
      ", PUNCT punct brought\n",
      "the DET det manager\n",
      "Wycombe PROPN compound manager\n",
      "manager NOUN nsubj brought\n",
      ", PUNCT punct manager\n",
      "Gareth PROPN compound Ainsworth\n",
      "Ainsworth PROPN appos manager\n",
      ", PUNCT punct manager\n",
      "brought VERB ROOT brought\n",
      "himself PRON dobj brought\n",
      "out ADP prep brought\n",
      "of ADP prep out\n",
      "retirement NOUN pobj of\n",
      "to PART aux play\n",
      "play VERB advcl brought\n",
      "in ADP prep play\n",
      "their PRON poss game\n",
      "Checkatrade PROPN compound Trophy\n",
      "Trophy PROPN compound game\n",
      "game NOUN pobj in\n",
      "against ADP prep game\n",
      "Northampton PROPN pobj against\n",
      "on ADP prep play\n",
      "30 NUM nummod August\n",
      "August PROPN pobj on\n",
      "2016 NUM nummod August\n",
      ", PUNCT punct brought\n",
      "having AUX aux hung\n",
      "hung VERB advcl brought\n",
      "up ADP prt hung\n",
      "his PRON poss boots\n",
      "boots NOUN dobj hung\n",
      "at ADP prep hung\n",
      "Adams PROPN compound Park\n",
      "Park PROPN pobj at\n",
      "on ADP prep hung\n",
      "27 NUM nummod April\n",
      "April PROPN pobj on\n",
      "2013 NUM nummod April\n",
      ". PUNCT punct brought\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)\n",
    "    \n",
    "# .dep_ digunakan untuk syntactic dependencies. \n",
    "# Penjelasan lengkap tentang istilah ini ada di https://universaldependencies.org/\n",
    "# nsubj: https://universaldependencies.org/en/dep/nsubj.html\n",
    "# ROOT: https://universaldependencies.org/en/dep/root.html\n",
    "# det: https://universaldependencies.org/en/dep/det.html\n",
    "# dobj: https://universaldependencies.org/docs/en/dep/dobj.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e7f453b-c7db-454c-9d50-6031006f1b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b4ae40ff5cd1420488541831b7c2be12-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">like</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">playing</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">soccer</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b4ae40ff5cd1420488541831b7c2be12-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b4ae40ff5cd1420488541831b7c2be12-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b4ae40ff5cd1420488541831b7c2be12-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b4ae40ff5cd1420488541831b7c2be12-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b4ae40ff5cd1420488541831b7c2be12-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b4ae40ff5cd1420488541831b7c2be12-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisasi\n",
    "# Catatan: Node.js sudah harus diinstall jika menggunakan Jupyter\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Load the small English pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process a text\n",
    "# doc = nlp(\"She ate the pizza\")\n",
    "doc = nlp(\"I like playing soccer\")\n",
    "\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)\n",
    "# dep => syntatic dependency - ketergantungan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e33d9a8-b028-4e4c-9d93-9922a81e5b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Due to an injury crisis, the Wycombe manager, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gareth Ainsworth\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", brought himself out of retirement to play in their Checkatrade Trophy game against \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Northampton\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    30 August 2016\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", having hung up his boots at \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Adams Park\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    27 April 2013\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". “[The appetite to play] never disappears and you always think you can do it,” said \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ainsworth\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". “I probably have to say thanks to my \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sunday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " league team as well because they have kept me pretty fit and I have not let the game go.” Thanks again to \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Joe\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " for that one.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Load the small English pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# text = \"\"\"In ancient Rome, some neighbors live in three adjacent houses. In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus. A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom. One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates). One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero. Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin).\"\"\"\n",
    "text = \"Due to an injury crisis, the Wycombe manager, Gareth Ainsworth, brought himself out of retirement to play in their Checkatrade Trophy game against Northampton on 30 August 2016, having hung up his boots at Adams Park on 27 April 2013. “[The appetite to play] never disappears and you always think you can do it,” said Ainsworth. “I probably have to say thanks to my Sunday league team as well because they have kept me pretty fit and I have not let the game go.” Thanks again to Joe for that one.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "# ent => entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29a85678-90c5-43e3-bc1d-5158489efabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark Zuckerberg’s PERSON\n",
      "Meta ORG\n",
      "Facebook ORG\n",
      "Instagram ORG\n",
      "WhatsApp ORG\n",
      "the Federal Trade Commission ORG\n",
      "FTC ORG\n",
      "second ORDINAL\n",
      "James Boasberg PERSON\n",
      "Tuesday DATE\n",
      "FTC ORG\n"
     ]
    }
   ],
   "source": [
    "# Process a text\n",
    "# doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "doc = nlp(\"Mark Zuckerberg’s Meta, the parent of Facebook, Instagram and WhatsApp, had asked a court to dismiss an antitrust complaint brought by the Federal Trade Commission (FTC) for the second time. However, Judge James Boasberg said on Tuesday that the FTC’s revised lawsuit should be allowed to proceed.\")\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and its label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93e4d845-24d4-42c4-9964-cd606eb68147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mark Zuckerberg’s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Meta\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", the parent of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Instagram\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    WhatsApp\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", had asked a court to dismiss an antitrust complaint brought by \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Federal Trade Commission\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    FTC\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ") for the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    second\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " time. However, Judge \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    James Boasberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " said on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tuesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " that the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    FTC\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s revised lawsuit should be allowed to proceed.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "879c8706-f6f4-4d3b-92a9-df2bb9813549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "656b4a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'People, including fictional'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"PERSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6cc26f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"first\", \"second\", etc.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ORDINAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b31cb498-d0fe-4573-95aa-da5042b49d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"GPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f51119af-76c7-4952-b101-7d643704b63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monetary values, including unit'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"MONEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0787f86-7998-4234-9d6a-8a6d7e581b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark        PROPN     compound  \n",
      "Zuckerberg  PROPN     poss      \n",
      "’s          PART      case      \n",
      "Meta        PROPN     nsubj     \n",
      ",           PUNCT     punct     \n",
      "the         DET       det       \n",
      "parent      NOUN      appos     \n",
      "of          ADP       prep      \n",
      "Facebook    PROPN     pobj      \n",
      ",           PUNCT     punct     \n",
      "Instagram   PROPN     conj      \n",
      "and         CCONJ     cc        \n",
      "WhatsApp    PROPN     conj      \n",
      ",           PUNCT     punct     \n",
      "had         AUX       aux       \n",
      "asked       VERB      ROOT      \n",
      "a           DET       det       \n",
      "court       NOUN      dobj      \n",
      "to          PART      aux       \n",
      "dismiss     VERB      xcomp     \n",
      "an          DET       det       \n",
      "antitrust   ADJ       amod      \n",
      "complaint   NOUN      dobj      \n",
      "brought     VERB      acl       \n",
      "by          ADP       agent     \n",
      "the         DET       det       \n",
      "Federal     PROPN     compound  \n",
      "Trade       PROPN     compound  \n",
      "Commission  PROPN     pobj      \n",
      "(           PUNCT     punct     \n",
      "FTC         PROPN     appos     \n",
      ")           PUNCT     punct     \n",
      "for         ADP       prep      \n",
      "the         DET       det       \n",
      "second      ADJ       amod      \n",
      "time        NOUN      pobj      \n",
      ".           PUNCT     punct     \n",
      "However     ADV       advmod    \n",
      ",           PUNCT     punct     \n",
      "Judge       PROPN     compound  \n",
      "James       PROPN     compound  \n",
      "Boasberg    PROPN     nsubj     \n",
      "said        VERB      ROOT      \n",
      "on          ADP       prep      \n",
      "Tuesday     PROPN     pobj      \n",
      "that        SCONJ     mark      \n",
      "the         DET       det       \n",
      "FTC         PROPN     poss      \n",
      "’s          PART      case      \n",
      "revised     VERB      amod      \n",
      "lawsuit     NOUN      nsubjpass \n",
      "should      AUX       aux       \n",
      "be          AUX       auxpass   \n",
      "allowed     VERB      ccomp     \n",
      "to          PART      aux       \n",
      "proceed     VERB      xcomp     \n",
      ".           PUNCT     punct     \n"
     ]
    }
   ],
   "source": [
    "# Format\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "text = \"Mark Zuckerberg’s Meta, the parent of Facebook, Instagram and WhatsApp, had asked a court to dismiss an antitrust complaint brought by the Federal Trade Commission (FTC) for the second time. However, Judge James Boasberg said on Tuesday that the FTC’s revised lawsuit should be allowed to proceed.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    print(f\"{token_text:<12}{token_pos:<10}{token_dep:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0744f86-a142-472e-a97e-2b6b404c762a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Missing entity: iPhone X\n"
     ]
    }
   ],
   "source": [
    "# Missing entity\n",
    "# Karena prediksi menggunakan statistika dan statistika tidak selalu benar\n",
    "# Semua tergantung pada data training\n",
    "# Contoh di bawah ini tidak mengenali iPhone X\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
    "# text = \"Facebook overtake Instagram with Meta.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and label\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# Get the span for \"iPhone X\"\n",
    "iphone_x = doc[1:3]\n",
    "\n",
    "# Print the span text\n",
    "print(\"Missing entity:\", iphone_x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76195e64-8298-4060-a7f7-0dc578da0b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9528407286733565721, 1, 3), (9528407286733565721, 3, 5), (9528407286733565721, 7, 9)]\n"
     ]
    }
   ],
   "source": [
    "# Rule-based Matching\n",
    "# Baca juga tentang Matcher API: https://spacy.io/api/matcher\n",
    "import spacy\n",
    "\n",
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load a pipeline and create the nlp object\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "matcher.add(\"IPHONE_PATTERN\", [pattern])\n",
    "\n",
    "# Process some text\n",
    "doc = nlp(\"Upcoming iPhone X iPhone X release date iPhone X leaked\")\n",
    "\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "print(matches)\n",
    "\n",
    "# hasil: match_id, start, end\n",
    "# Upcoming => 0\n",
    "# iPhone => 1\n",
    "# X => 2\n",
    "# [1,3] => 1 sampai 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afadc7a7-ec63-482a-983e-f08c581fac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n",
      "iPhone X\n",
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "23b692ca-84d9-4084-8653-4b77df09036e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 FIFA World Cup:\n",
      "2018 FIFA World Cup: France\n",
      "2018 FIFA World Cup: France won\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"IS_DIGIT\": True},\n",
    "    {\"LOWER\": \"fifa\"},\n",
    "    {\"LOWER\": \"world\"},\n",
    "    {\"LOWER\": \"cup\"},\n",
    "    {\"IS_PUNCT\": True},\n",
    "    {\"IS_TITLE\": True},\n",
    "    {\"LOWER\": \"won\"}\n",
    "]\n",
    "doc = nlp(\"2018 FIFA World Cup: France won!\")\n",
    "matcher.add(\"FIFA_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1566ef78-34c9-4384-a131-3db261aa0138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loved dogs\n",
      "love cats\n",
      "love soccer\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"LEMMA\": \"love\", \"POS\": \"VERB\"},\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "doc = nlp(\"I loved dogs but now I love cats more. I also love soccer!\")\n",
    "matcher.add(\"ANIMAL_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "73fb7265-a87c-4401-a53c-8f2309ec43c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought a smartphone\n",
      "buying apps\n"
     ]
    }
   ],
   "source": [
    "pattern = [\n",
    "    {\"LEMMA\": \"buy\"},\n",
    "    {\"POS\": \"DET\", \"OP\": \"?\"},  # optional: match 0 or 1 times\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "doc = nlp(\"I bought a smartphone. Now I'm buying apps.\")\n",
    "matcher.add(\"PHONE_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
